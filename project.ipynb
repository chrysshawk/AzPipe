{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import azureml.core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current workspace: ml-workspace\n"
     ]
    }
   ],
   "source": [
    "# assign current workspace\n",
    "from azureml.core import Workspace\n",
    "ws = Workspace.from_config()\n",
    "print('Current workspace:', ws.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current datastore: workspaceblobstore\n"
     ]
    }
   ],
   "source": [
    "# assign datastore\n",
    "ds = ws.get_default_datastore()\n",
    "print('Current datastore:', ds.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 1 files\n",
      "Uploading ./data/heart.csv\n",
      "Uploaded ./data/heart.csv, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n"
     ]
    },
    {
     "data": {
      "text/plain": "$AZUREML_DATAREFERENCE_e443c5dbeec54c4e9850737773070739"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# upload the file to blob\n",
    "ds.upload_files(files=['./data/heart.csv'], target_path='data-heart/', overwrite=True, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already registered.\n"
     ]
    }
   ],
   "source": [
    "# register the dataset\n",
    "from azureml.core import Dataset\n",
    "\n",
    "# name of our dataset\n",
    "ds_name = 'heart dataset'\n",
    "\n",
    "if 'heart dataset' not in ws.datasets:\n",
    "    # create tabular dataset from the data\n",
    "    heart_data = Dataset.Tabular.from_delimited_files(path=(ds, 'data-heart/*.csv'))\n",
    "\n",
    "    # register the dataset\n",
    "    try:\n",
    "        heart_data = heart_data.register(workspace=ws,\n",
    "                                         name = ds_name,\n",
    "                                         description= 'Heart Attach Data',\n",
    "                                         tags = {'format' : 'csv'},\n",
    "                                         create_new_version = True)\n",
    "        print('Dataset %s registered with version %i.'%(heart_data.name, str(heart_data.version)))\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "else:\n",
    "    print('Dataset already registered.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./heart_pipeline\n"
     ]
    }
   ],
   "source": [
    "# Create a local folder for the pipeline step files\n",
    "\n",
    "import os\n",
    "experiment_folder = './heart_pipeline'\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "print(experiment_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Step 1: Prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./heart_pipeline/01_prep_heart.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/01_prep_heart.py\n",
    "# Import libraries\n",
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from azureml.core import Run\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Get parameters\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--input-data', type=str, dest='raw_dataset_id',\n",
    "                    help='raw dataset')\n",
    "parser.add_argument('--prepped-data', type=str, dest='prepped_data',\n",
    "                    default='prepped_data',\n",
    "                    help='Folder for results')\n",
    "args = parser.parse_args()\n",
    "save_folder = args.prepped_data\n",
    "\n",
    "# Get experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# Load data\n",
    "print('Loading Data...')\n",
    "heart_df = run.input_datasets['raw_data'].to_pandas_dataframe()\n",
    "\n",
    "# Log raw dataset details\n",
    "run.log('Raw rows', heart_df.shape[0])\n",
    "run.log('Raw columns', heart_df.shape[1])\n",
    "\n",
    "# Drop NAs\n",
    "heart_df = heart_df.dropna()\n",
    "\n",
    "# Modifying prediction label\n",
    "heart_df.rename(columns={'output' : 'heart_attack'}, inplace=True)\n",
    "\n",
    "# Change sex categorical feature to dummies\n",
    "sex_type = pd.get_dummies(data=heart_df['sex'])\n",
    "sex_type.columns = ['Male', 'Female']\n",
    "chest_pain = pd.get_dummies(data=heart_df['cp'])\n",
    "chest_pain.columns = ['Chest Pain 1', 'Chest Pain 2', 'Chest Pain 3',\n",
    "                      'Chest Pain 4']\n",
    "ex_angina = pd.get_dummies(data=heart_df['exng'])\n",
    "ex_angina.columns = ['Exercise Angina: No', 'Exercise Angina: Yes']\n",
    "slp_type = pd.get_dummies(data=heart_df['slp'])\n",
    "slp_type.columns = ['Slope 1', 'Slope 2', 'Slope 3']\n",
    "caa_type = pd.get_dummies(data=heart_df['caa'])\n",
    "caa_type.columns = ['CAA 1', 'CAA 2', 'CAA 3', 'CAA 4', 'CAA 5']\n",
    "thall_type = pd.get_dummies(data=heart_df['thall'])\n",
    "thall_type.columns = ['Thall 1', 'Thall 2', 'Thall 3', 'Thall 4']\n",
    "\n",
    "\n",
    "# Joining and removing modified columns\n",
    "heart_df = pd.concat([sex_type, chest_pain, ex_angina, slp_type,\n",
    "                      caa_type, thall_type, heart_df],\n",
    "                     axis=1)\n",
    "heart_df.drop(labels=['sex', 'cp', 'exng', 'slp', 'caa', 'thall'], \n",
    "              axis=1, inplace=True)\n",
    "\n",
    "# Normalize numeric columns\n",
    "scaler = MinMaxScaler()\n",
    "norm_cols = ['age', 'trtbps', 'chol', 'fbs', 'restecg', 'thalachh',\n",
    "                'oldpeak']\n",
    "heart_df[norm_cols] = scaler.fit_transform(heart_df[norm_cols])\n",
    "\n",
    "# Log prepped dataset details\n",
    "run.log('Prepped rows', heart_df.shape[0])\n",
    "run.log('Prepped columns', heart_df.shape[1])\n",
    "\n",
    "# Save the prepped data\n",
    "print('Saving Data...')\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "save_path = os.path.join(save_folder, 'heartdata_prepped.csv')\n",
    "heart_df.to_csv(save_path, index=False, header=True)\n",
    "\n",
    "# End the run\n",
    "run.complete()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Step 2: Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./heart_pipeline/02_train_heart.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/02_train_heart.py\n",
    "\n",
    "# Import libraries\n",
    "from azureml.core import Run, Model\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get parameters\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--training-data',\n",
    "                    type=str,\n",
    "                    dest='training_data',\n",
    "                    help='training_data')\n",
    "args = parser.parse_args()\n",
    "training_data = args.training_data\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# Load the data\n",
    "print('Loading Data...')\n",
    "file_path = os.path.join(training_data, 'heartdata_prepped.csv')\n",
    "heart = pd.read_csv(file_path)\n",
    "\n",
    "# Separate features from labels\n",
    "X, y = heart.iloc[:,0:-1].values, heart.iloc[:,-1]\n",
    "\n",
    "# Split data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,\n",
    "                                                    random_state=0)\n",
    "\n",
    "# Train model\n",
    "print('Training model...')\n",
    "model = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "\n",
    "# Calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# Calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test, y_scores[:,1])\n",
    "print('AUC:', auc)\n",
    "run.log('AUC', np.float(auc))\n",
    "\n",
    "# Plot ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\n",
    "fig = plt.figure(figsize=(6,4))\n",
    "plt.plot([0,1], [0,1], 'k--') # diagonal 50% line\n",
    "plt.plot(fpr, tpr, 'r--')\n",
    "plt.xlabel('FP rate')\n",
    "plt.ylabel('TP rate')\n",
    "plt.title('ROC Curve')\n",
    "run.log_image(name='ROC', plot=fig)\n",
    "plt.show()\n",
    "\n",
    "# Save trained model \n",
    "print('Saving model...')\n",
    "os.makedirs('./outputs', exist_ok=True)\n",
    "model_file = os.path.join('./outputs', 'heart_model.pkl')\n",
    "joblib.dump(value=model, filename=model_file)\n",
    "\n",
    "# Register model\n",
    "print('Registering model...')\n",
    "Model.register(workspace = run.experiment.workspace,\n",
    "               model_path = model_file,\n",
    "               model_name = 'heart_model',\n",
    "               tags = {'Context' : 'Pipeline',\n",
    "                       'Purpose' : 'DP100'},\n",
    "               properties = {'AUC' : np.float(auc),\n",
    "                             'Accuracy' : np.float(acc)})\n",
    "               \n",
    "run.complete()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep compute environment\n",
    "\n",
    "This is only necessary if a compute environment is required (i.e. it will not run locally)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, using it.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "cluster_name = 'chryssCluster'\n",
    "\n",
    "try:\n",
    "    pipeline_cluster = ComputeTarget(workspace=ws,\n",
    "                                     name=cluster_name)\n",
    "    print('Found existing cluster, using it.')\n",
    "except:\n",
    "    # It does not exist, create it\n",
    "    try:\n",
    "        compute_config = AmlCompute.provisioning_configuration(\n",
    "            vm_size='STANDARD_DS11_V2',\n",
    "            max_nodes=2)\n",
    "        pipeline_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "        pipeline_cluster.wait_for_completion(show_output=True)\n",
    "    except Exception as ex:\n",
    "        print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create conda environment config\n",
    "\n",
    "This will be installed on the compute target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./heart_pipeline/heart_experiment_env.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/heart_experiment_env.yml\n",
    "name: heart_experiment_env\n",
    "dependencies:\n",
    "- python=3.6.2\n",
    "- scikit-learn\n",
    "- ipykernel\n",
    "- matplotlib\n",
    "- pandas\n",
    "- pip\n",
    "- pip:\n",
    "    - azureml-defaults\n",
    "    - pyarrow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create run configuration: Environment & Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run configuration created.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "\n",
    "heart_experiment_env = Environment.from_conda_specification(\n",
    "    'heart_experiment_env', experiment_folder + '/heart_experiment_env.yml')\n",
    "\n",
    "# Register environment\n",
    "heart_experiment_env.register(workspace=ws)\n",
    "registered_env = Environment.get(ws, 'heart_experiment_env')\n",
    "\n",
    "# Create RunConfig object for pipeline\n",
    "pipeline_run_config = RunConfiguration()\n",
    "pipeline_run_config.target = pipeline_cluster\n",
    "pipeline_run_config.environment = registered_env\n",
    "\n",
    "print('Run configuration created.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and run pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline steps defined.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Please specify a remote compute_target. (Local execution is not supported for pipelines.)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-494c4b8dd818>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# Construct pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mpipeline_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mprep_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpipeline_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Pipeline is built.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ch_azure/lib/python3.8/site-packages/azureml/core/_experiment_method.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \"\"\"\n\u001b[1;32m    103\u001b[0m             \u001b[0mExperimentSubmitRegistrar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_submit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubmit_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0minit_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mreal_decorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ch_azure/lib/python3.8/site-packages/azureml/pipeline/core/pipeline.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, workspace, steps, description, default_datastore, default_source_directory, resolve_closure, _workflow_provider, _service_endpoint, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'parameter %s is not recognized for Pipeline '\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_email_notification\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menable_email_notification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_builder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_experiment_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ch_azure/lib/python3.8/site-packages/azureml/pipeline/core/builder.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, name, steps, finalize, regenerate_outputs)\u001b[0m\n\u001b[1;32m   1479\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1481\u001b[0;31m         \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1482\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m             \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregenerate_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregenerate_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ch_azure/lib/python3.8/site-packages/azureml/pipeline/core/builder.py\u001b[0m in \u001b[0;36mconstruct\u001b[0;34m(self, name, steps)\u001b[0m\n\u001b[1;32m   1501\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1502\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodeStack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1503\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1504\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbuilder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_builderStack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1505\u001b[0m             \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_rules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ch_azure/lib/python3.8/site-packages/azureml/pipeline/core/builder.py\u001b[0m in \u001b[0;36mprocess_collection\u001b[0;34m(self, collection)\u001b[0m\n\u001b[1;32m   1537\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodeStack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1538\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_builderStack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1539\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1540\u001b[0m         \u001b[0madded_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodeStack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1541\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodeStack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madded_nodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ch_azure/lib/python3.8/site-packages/azureml/pipeline/core/builder.py\u001b[0m in \u001b[0;36mprocess_collection\u001b[0;34m(self, collection)\u001b[0m\n\u001b[1;32m   1828\u001b[0m         \"\"\"\n\u001b[1;32m   1829\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollection\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1830\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base_builder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1832\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_rules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ch_azure/lib/python3.8/site-packages/azureml/pipeline/core/builder.py\u001b[0m in \u001b[0;36mprocess_collection\u001b[0;34m(self, collection)\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;31m# just a step?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1532\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPipelineStep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1533\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1535\u001b[0m         \u001b[0;31m# delegate to correct builder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ch_azure/lib/python3.8/site-packages/azureml/pipeline/core/builder.py\u001b[0m in \u001b[0;36mprocess_step\u001b[0;34m(self, step)\u001b[0m\n\u001b[1;32m   1575\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step2node\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1577\u001b[0;31m         \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_datastore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1578\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_node_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ch_azure/lib/python3.8/site-packages/azureml/pipeline/steps/python_script_step.py\u001b[0m in \u001b[0;36mcreate_node\u001b[0;34m(self, graph, default_datastore, context)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mazureml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \"\"\"\n\u001b[0;32m--> 243\u001b[0;31m         return super(PythonScriptStep, self).create_node(\n\u001b[0m\u001b[1;32m    244\u001b[0m             graph=graph, default_datastore=default_datastore, context=context)\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ch_azure/lib/python3.8/site-packages/azureml/pipeline/core/_python_script_step_base.py\u001b[0m in \u001b[0;36mcreate_node\u001b[0;34m(self, graph, default_datastore, context)\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mcompute_target_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_target_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_target_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_target\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0mcompute_target_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_target_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_target_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_PythonScriptStepBase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m                 \u001b[0m_extract_compute_target_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_runconfig\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ch_azure/lib/python3.8/site-packages/azureml/pipeline/core/_python_script_step_base.py\u001b[0m in \u001b[0;36m_extract_compute_target_params\u001b[0;34m(context, compute_target)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompute_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0mcompute_target_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m             \u001b[0mcompute_target_object\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompute_target_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m             \u001b[0mcompute_target_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_target_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompute_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ch_azure/lib/python3.8/site-packages/azureml/pipeline/core/_graph_context.py\u001b[0m in \u001b[0;36mget_target\u001b[0;34m(self, target_name)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtarget_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mLOCAL_RUNCONFIG_NAME\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 raise ValueError(\"Please specify a remote compute_target. \"\n\u001b[0m\u001b[1;32m     66\u001b[0m                                  \"(Local execution is not supported for pipelines.)\")\n\u001b[1;32m     67\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Please specify a remote compute_target. (Local execution is not supported for pipelines.)"
     ]
    }
   ],
   "source": [
    "from azureml.data import OutputFileDatasetConfig\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "from azureml.pipeline.core import Pipeline\n",
    "\n",
    "# Get the dataset\n",
    "heart_ds = ws.datasets.get('heart dataset')\n",
    "\n",
    "# Create OutputFileDatasetConfig (temp data)\n",
    "prepped_data = OutputFileDatasetConfig('prepped_data')\n",
    "\n",
    "# Create steps\n",
    "prep_step = PythonScriptStep(name = 'Prepare Data',\n",
    "                                source_directory = experiment_folder,\n",
    "                                script_name = '01_prep_heart.py',\n",
    "                                arguments = ['--input-data', heart_ds.as_named_input('raw_data'),\n",
    "                                             '--prepped-data', prepped_data],\n",
    "                                compute_target = pipeline_cluster,\n",
    "                                runconfig = pipeline_run_config,\n",
    "                                allow_reuse = True)\n",
    "train_step = PythonScriptStep(name = 'Train and Register Model',\n",
    "                                 source_directory = experiment_folder,\n",
    "                                 script_name = '02_train_heart.py',\n",
    "                                 arguments = ['--training-data',\n",
    "                                              prepped_data.as_input()],\n",
    "                                 compute_target = pipeline_cluster,\n",
    "                                 runconfig = pipeline_run_config,\n",
    "                                 allow_reuse = True)\n",
    "\n",
    "\n",
    "\n",
    "print('Pipeline steps defined.')\n",
    "\n",
    "# Construct pipeline\n",
    "pipeline_steps = [prep_step, train_step]\n",
    "pipeline = Pipeline(workspace=ws, steps=pipeline_steps)\n",
    "print('Pipeline is built.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Pipeline and Run as Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step Prepare Data [a78d125a][630e597f-bda4-4e70-8cfd-192aba194723], (This step will run and generate new outputs)Created step Train and Register Model [485b1955][54fd40ec-95d2-4e80-a14c-e8bb8568b70c], (This step will run and generate new outputs)\n",
      "\n",
      "Submitted PipelineRun 4064b1ee-5145-4bc7-9c29-6577b96a7c62\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/4064b1ee-5145-4bc7-9c29-6577b96a7c62?wsid=/subscriptions/1b50f243-9e15-4373-91f7-59060f79af8a/resourcegroups/DP-100/workspaces/ml-workspace&tid=186e418a-457a-46b9-aa3b-0336d2e46f5b\n",
      "Pipeline submitted for execution.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d08ef11c465a4559b36e3734e0022dd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', â€¦"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/4064b1ee-5145-4bc7-9c29-6577b96a7c62?wsid=/subscriptions/1b50f243-9e15-4373-91f7-59060f79af8a/resourcegroups/DP-100/workspaces/ml-workspace&tid=186e418a-457a-46b9-aa3b-0336d2e46f5b\", \"run_id\": \"4064b1ee-5145-4bc7-9c29-6577b96a7c62\", \"run_properties\": {\"run_id\": \"4064b1ee-5145-4bc7-9c29-6577b96a7c62\", \"created_utc\": \"2021-07-22T11:26:28.008032Z\", \"properties\": {\"azureml.runsource\": \"azureml.PipelineRun\", \"runSource\": \"SDK\", \"runType\": \"SDK\", \"azureml.parameters\": \"{}\"}, \"tags\": {\"azureml.pipelineComponent\": \"pipelinerun\"}, \"end_time_utc\": \"2021-07-22T11:33:58.562461Z\", \"status\": \"Completed\", \"log_files\": {\"logs/azureml/executionlogs.txt\": \"https://mlworkspace1398408280.blob.core.windows.net/azureml/ExperimentRun/dcid.4064b1ee-5145-4bc7-9c29-6577b96a7c62/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=dDXncUz5EHggXMjCOIUfEe9NFxNgln8QlA%2Fskx2YDdE%3D&st=2021-07-22T11%3A16%3A52Z&se=2021-07-22T19%3A26%3A52Z&sp=r\", \"logs/azureml/stderrlogs.txt\": \"https://mlworkspace1398408280.blob.core.windows.net/azureml/ExperimentRun/dcid.4064b1ee-5145-4bc7-9c29-6577b96a7c62/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=MsjmmwQLr0TVXTVM4lmXoVodClvnv6r6IKvpWPyxclg%3D&st=2021-07-22T11%3A16%3A52Z&se=2021-07-22T19%3A26%3A52Z&sp=r\", \"logs/azureml/stdoutlogs.txt\": \"https://mlworkspace1398408280.blob.core.windows.net/azureml/ExperimentRun/dcid.4064b1ee-5145-4bc7-9c29-6577b96a7c62/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=yb%2Ffr3plzGWQ3yblLyZZtVdQP3vK6PMp62cYGHZJE3k%3D&st=2021-07-22T11%3A16%3A52Z&se=2021-07-22T19%3A26%3A52Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/executionlogs.txt\", \"logs/azureml/stderrlogs.txt\", \"logs/azureml/stdoutlogs.txt\"]], \"run_duration\": \"0:07:30\", \"run_number\": \"13\", \"run_queued_details\": {\"status\": \"Finished\", \"details\": null}}, \"child_runs\": [{\"run_id\": \"c8c116f6-2804-4b40-ba94-7c9c1b69e2b4\", \"name\": \"Prepare Data\", \"status\": \"Finished\", \"start_time\": \"2021-07-22T11:31:33.960487Z\", \"created_time\": \"2021-07-22T11:26:32.322355Z\", \"end_time\": \"2021-07-22T11:33:08.686613Z\", \"duration\": \"0:06:36\", \"run_number\": 14, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-07-22T11:26:32.322355Z\", \"is_reused\": \"\"}, {\"run_id\": \"cd8085b2-58e9-4a1e-ba14-29a8bb10533c\", \"name\": \"Train and Register Model\", \"status\": \"Finished\", \"start_time\": \"2021-07-22T11:33:23.065684Z\", \"created_time\": \"2021-07-22T11:33:13.341342Z\", \"end_time\": \"2021-07-22T11:33:56.03064Z\", \"duration\": \"0:00:42\", \"run_number\": 15, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-07-22T11:33:13.341342Z\", \"is_reused\": \"\"}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2021-07-22 11:26:32Z] Submitting 1 runs, first five are: a78d125a:c8c116f6-2804-4b40-ba94-7c9c1b69e2b4\\n[2021-07-22 11:33:13Z] Completing processing run id c8c116f6-2804-4b40-ba94-7c9c1b69e2b4.\\n[2021-07-22 11:33:13Z] Submitting 1 runs, first five are: 485b1955:cd8085b2-58e9-4a1e-ba14-29a8bb10533c\\n[2021-07-22 11:33:58Z] Completing processing run id cd8085b2-58e9-4a1e-ba14-29a8bb10533c.\\n\\nRun is completed.\", \"graph\": {\"datasource_nodes\": {\"8bfcd5e8\": {\"node_id\": \"8bfcd5e8\", \"name\": \"heart dataset\"}}, \"module_nodes\": {\"a78d125a\": {\"node_id\": \"a78d125a\", \"name\": \"Prepare Data\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"c8c116f6-2804-4b40-ba94-7c9c1b69e2b4\"}, \"485b1955\": {\"node_id\": \"485b1955\", \"name\": \"Train and Register Model\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"cd8085b2-58e9-4a1e-ba14-29a8bb10533c\"}}, \"edges\": [{\"source_node_id\": \"8bfcd5e8\", \"source_node_name\": \"heart dataset\", \"source_name\": \"data\", \"target_name\": \"raw_data\", \"dst_node_id\": \"a78d125a\", \"dst_node_name\": \"Prepare Data\"}, {\"source_node_id\": \"a78d125a\", \"source_node_name\": \"Prepare Data\", \"source_name\": \"prepped_data\", \"target_name\": \"input_232442b6\", \"dst_node_id\": \"485b1955\", \"dst_node_name\": \"Train and Register Model\"}], \"child_runs\": [{\"run_id\": \"c8c116f6-2804-4b40-ba94-7c9c1b69e2b4\", \"name\": \"Prepare Data\", \"status\": \"Finished\", \"start_time\": \"2021-07-22T11:31:33.960487Z\", \"created_time\": \"2021-07-22T11:26:32.322355Z\", \"end_time\": \"2021-07-22T11:33:08.686613Z\", \"duration\": \"0:06:36\", \"run_number\": 14, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-07-22T11:26:32.322355Z\", \"is_reused\": \"\"}, {\"run_id\": \"cd8085b2-58e9-4a1e-ba14-29a8bb10533c\", \"name\": \"Train and Register Model\", \"status\": \"Finished\", \"start_time\": \"2021-07-22T11:33:23.065684Z\", \"created_time\": \"2021-07-22T11:33:13.341342Z\", \"end_time\": \"2021-07-22T11:33:56.03064Z\", \"duration\": \"0:00:42\", \"run_number\": 15, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-07-22T11:33:13.341342Z\", \"is_reused\": \"\"}]}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.31.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineRunId: 4064b1ee-5145-4bc7-9c29-6577b96a7c62\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/4064b1ee-5145-4bc7-9c29-6577b96a7c62?wsid=/subscriptions/1b50f243-9e15-4373-91f7-59060f79af8a/resourcegroups/DP-100/workspaces/ml-workspace&tid=186e418a-457a-46b9-aa3b-0336d2e46f5b\n",
      "{'runId': '4064b1ee-5145-4bc7-9c29-6577b96a7c62', 'status': 'Completed', 'startTimeUtc': '2021-07-22T11:26:29.703057Z', 'endTimeUtc': '2021-07-22T11:33:58.562461Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://mlworkspace1398408280.blob.core.windows.net/azureml/ExperimentRun/dcid.4064b1ee-5145-4bc7-9c29-6577b96a7c62/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=dDXncUz5EHggXMjCOIUfEe9NFxNgln8QlA%2Fskx2YDdE%3D&st=2021-07-22T11%3A16%3A52Z&se=2021-07-22T19%3A26%3A52Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mlworkspace1398408280.blob.core.windows.net/azureml/ExperimentRun/dcid.4064b1ee-5145-4bc7-9c29-6577b96a7c62/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=MsjmmwQLr0TVXTVM4lmXoVodClvnv6r6IKvpWPyxclg%3D&st=2021-07-22T11%3A16%3A52Z&se=2021-07-22T19%3A26%3A52Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mlworkspace1398408280.blob.core.windows.net/azureml/ExperimentRun/dcid.4064b1ee-5145-4bc7-9c29-6577b96a7c62/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=yb%2Ffr3plzGWQ3yblLyZZtVdQP3vK6PMp62cYGHZJE3k%3D&st=2021-07-22T11%3A16%3A52Z&se=2021-07-22T19%3A26%3A52Z&sp=r'}, 'submittedBy': 'Christoffer Haukvik'}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Finished'"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "# Create an experiment and run pipeline\n",
    "experiment = Experiment(workspace=ws, name='heart_pipeline')\n",
    "pipeline_run = experiment.submit(pipeline, regenerate_outputs=True)\n",
    "print('Pipeline submitted for execution.')\n",
    "RunDetails(pipeline_run).show()\n",
    "pipeline_run.wait_for_completion(show_output=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine Experiment run metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and Register Model :\n",
      "\t Accuracy : 0.7692307692307693\n",
      "\t AUC : 0.7678916827852998\n",
      "\t ROC : aml://artifactId/ExperimentRun/dcid.cd8085b2-58e9-4a1e-ba14-29a8bb10533c/ROC_1626953622.png\n",
      "Prepare Data :\n",
      "\t Raw rows : 303\n",
      "\t Raw columns : 14\n",
      "\t Prepped rows : 303\n",
      "\t Prepped columns : 28\n"
     ]
    }
   ],
   "source": [
    "for run in pipeline_run.get_children():\n",
    "    print(run.name, ':')\n",
    "    metrics = run.get_metrics()\n",
    "    for metric_name in metrics:\n",
    "        print('\\t', metric_name, ':', metrics[metric_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heart_model\n",
      "{'Context': 'Pipeline', 'Purpose': 'DP100'}\n",
      "{'AUC': '0.745164410058027', 'Accuracy': '0.7472527472527473'}\n"
     ]
    }
   ],
   "source": [
    "for model in Model.list(workspace=ws, name='heart_model'):\n",
    "    print(model.name)\n",
    "    print(model.tags)\n",
    "    print(model.properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Publish the pipeline as REST service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<table style=\"width:100%\"><tr><th>Name</th><th>Id</th><th>Status</th><th>Endpoint</th></tr><tr><td>heart-training-pipeline</td><td><a href=\"https://ml.azure.com/pipelines/e9ad0b74-22cf-444e-a29b-3bb1ad7d1e64?wsid=/subscriptions/1b50f243-9e15-4373-91f7-59060f79af8a/resourcegroups/DP-100/workspaces/ml-workspace\" target=\"_blank\" rel=\"noopener\">e9ad0b74-22cf-444e-a29b-3bb1ad7d1e64</a></td><td>Active</td><td><a href=\"https://westeurope.api.azureml.ms/pipelines/v1.0/subscriptions/1b50f243-9e15-4373-91f7-59060f79af8a/resourceGroups/DP-100/providers/Microsoft.MachineLearningServices/workspaces/ml-workspace/PipelineRuns/PipelineSubmit/e9ad0b74-22cf-444e-a29b-3bb1ad7d1e64\" target=\"_blank\" rel=\"noopener\">REST Endpoint</a></td></tr></table>",
      "text/plain": "Pipeline(Name: heart-training-pipeline,\nId: e9ad0b74-22cf-444e-a29b-3bb1ad7d1e64,\nStatus: Active,\nEndpoint: https://westeurope.api.azureml.ms/pipelines/v1.0/subscriptions/1b50f243-9e15-4373-91f7-59060f79af8a/resourceGroups/DP-100/providers/Microsoft.MachineLearningServices/workspaces/ml-workspace/PipelineRuns/PipelineSubmit/e9ad0b74-22cf-444e-a29b-3bb1ad7d1e64)"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pub_pipeline = pipeline_run.publish_pipeline(\n",
    "    name = 'heart-training-pipeline',\n",
    "    description = 'Trains heart model',\n",
    "    version = '1.0'\n",
    ")\n",
    "pub_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://westeurope.api.azureml.ms/pipelines/v1.0/subscriptions/1b50f243-9e15-4373-91f7-59060f79af8a/resourceGroups/DP-100/providers/Microsoft.MachineLearningServices/workspaces/ml-workspace/PipelineRuns/PipelineSubmit/e9ad0b74-22cf-444e-a29b-3bb1ad7d1e64\n"
     ]
    }
   ],
   "source": [
    "rest_endpoint = pub_pipeline.endpoint\n",
    "print(rest_endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consume Endpoint\n",
    "\n",
    "We need to get the authorization header in order to access the endpoint; this will be provided in the request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentication header is ready.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "\n",
    "interactive_auth = InteractiveLoginAuthentication()\n",
    "auth_header = interactive_auth.get_authentication_header()\n",
    "print('Authentication header is ready.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunID: b3259353-3971-42a4-b2dd-c9d32b917a55\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "experiment_name = 'heart_pipeline' # name of the pipeline\n",
    "rest_endpoint = pub_pipeline.endpoint # endpoint\n",
    "response = requests.post(rest_endpoint,\n",
    "                         headers=auth_header,\n",
    "                         json={'ExperimentName' : experiment_name})\n",
    "run_id = response.json()['Id']\n",
    "print('RunID:', run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use this RunID to get the data from the PipelineRun.  \n",
    "**Note:** This should complete quickly since each step was configured to allow output reuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineRunId: b3259353-3971-42a4-b2dd-c9d32b917a55\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/b3259353-3971-42a4-b2dd-c9d32b917a55?wsid=/subscriptions/1b50f243-9e15-4373-91f7-59060f79af8a/resourcegroups/DP-100/workspaces/ml-workspace&tid=186e418a-457a-46b9-aa3b-0336d2e46f5b\n",
      "PipelineRun Status: Running\n",
      "\n",
      "PipelineRun Execution Summary\n",
      "==============================\n",
      "PipelineRun Status: Finished\n",
      "{'runId': 'b3259353-3971-42a4-b2dd-c9d32b917a55', 'status': 'Completed', 'startTimeUtc': '2021-07-21T11:35:58.949229Z', 'endTimeUtc': '2021-07-21T11:36:02.265859Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'Unavailable', 'runType': 'HTTP', 'azureml.parameters': '{}', 'azureml.pipelineid': 'e9ad0b74-22cf-444e-a29b-3bb1ad7d1e64'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://mlworkspace1398408280.blob.core.windows.net/azureml/ExperimentRun/dcid.b3259353-3971-42a4-b2dd-c9d32b917a55/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=7uOn%2FijFtVRdOriiEEkm2RaeMBniSvIpuj59Hk1C5uc%3D&st=2021-07-21T11%3A26%3A03Z&se=2021-07-21T19%3A36%3A03Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mlworkspace1398408280.blob.core.windows.net/azureml/ExperimentRun/dcid.b3259353-3971-42a4-b2dd-c9d32b917a55/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=HRbFWZUTOW90S%2BpTQKA2OpN3L5Jm9GsdFzC3FXaWp%2B8%3D&st=2021-07-21T11%3A26%3A03Z&se=2021-07-21T19%3A36%3A03Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mlworkspace1398408280.blob.core.windows.net/azureml/ExperimentRun/dcid.b3259353-3971-42a4-b2dd-c9d32b917a55/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=3oH%2BlCboXHJgzkKH2jQK0FWshklSkrRnoL32BSFmT90%3D&st=2021-07-21T11%3A26%3A03Z&se=2021-07-21T19%3A36%3A03Z&sp=r'}, 'submittedBy': 'Christoffer Haukvik'}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "'Finished'"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.pipeline.core.run import PipelineRun\n",
    "\n",
    "pub_pipeline_run = PipelineRun(ws.experiments[experiment_name], run_id)\n",
    "pub_pipeline_run.wait_for_completion(show_output=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scheduling and get the latest run\n",
    "\n",
    "Notebook \"08 - Create a Pipeline\" details how to schedule in Python.\n",
    "\n",
    "We will not set it up here, but if it were, we would need to fetch the details from the latest run. This is done below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{'runId': 'b3259353-3971-42a4-b2dd-c9d32b917a55',\n 'status': 'Completed',\n 'startTimeUtc': '2021-07-21T11:35:58.949229Z',\n 'endTimeUtc': '2021-07-21T11:36:02.265859Z',\n 'properties': {'azureml.runsource': 'azureml.PipelineRun',\n  'runSource': 'Unavailable',\n  'runType': 'HTTP',\n  'azureml.parameters': '{}',\n  'azureml.pipelineid': 'e9ad0b74-22cf-444e-a29b-3bb1ad7d1e64'},\n 'inputDatasets': [],\n 'outputDatasets': [],\n 'logFiles': {'logs/azureml/executionlogs.txt': 'https://mlworkspace1398408280.blob.core.windows.net/azureml/ExperimentRun/dcid.b3259353-3971-42a4-b2dd-c9d32b917a55/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=7uOn%2FijFtVRdOriiEEkm2RaeMBniSvIpuj59Hk1C5uc%3D&st=2021-07-21T11%3A26%3A03Z&se=2021-07-21T19%3A36%3A03Z&sp=r',\n  'logs/azureml/stderrlogs.txt': 'https://mlworkspace1398408280.blob.core.windows.net/azureml/ExperimentRun/dcid.b3259353-3971-42a4-b2dd-c9d32b917a55/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=HRbFWZUTOW90S%2BpTQKA2OpN3L5Jm9GsdFzC3FXaWp%2B8%3D&st=2021-07-21T11%3A26%3A03Z&se=2021-07-21T19%3A36%3A03Z&sp=r',\n  'logs/azureml/stdoutlogs.txt': 'https://mlworkspace1398408280.blob.core.windows.net/azureml/ExperimentRun/dcid.b3259353-3971-42a4-b2dd-c9d32b917a55/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=3oH%2BlCboXHJgzkKH2jQK0FWshklSkrRnoL32BSFmT90%3D&st=2021-07-21T11%3A26%3A03Z&se=2021-07-21T19%3A36%3A03Z&sp=r'},\n 'submittedBy': 'Christoffer Haukvik'}"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_experiment = ws.experiments.get('heart_pipeline')\n",
    "latest_run = list(pipeline_experiment.get_runs())[0]\n",
    "latest_run.get_details()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('ch_azure': conda)",
   "name": "python3810jvsc74a57bd05a32c7bc2300999b8fb3e0da655551b24b48d1e812c311f299692aa0706723be"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "metadata": {
   "interpreter": {
    "hash": "5a32c7bc2300999b8fb3e0da655551b24b48d1e812c311f299692aa0706723be"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}